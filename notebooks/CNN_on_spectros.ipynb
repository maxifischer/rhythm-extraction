{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import madmom\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocessing import get_dataset\n",
    "from models import OLSPatchRegressor\n",
    "\n",
    "na = np.newaxis\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Shape\n",
      "(128, 74, 1500, 1) (128,)\n"
     ]
    }
   ],
   "source": [
    "music_dir  = '../data/music_speech/music_wav/'\n",
    "speech_dir = '../data/music_speech/speech_wav/'\n",
    "\n",
    "max_samples = -1\n",
    "\n",
    "X, Y = get_dataset(music_dir, speech_dir, num_samples=max_samples, hpool=0, wpool=0)\n",
    "print('Train Set Shape')\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "Y = (Y + 1) / 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN using KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_classes = 2\n",
    "epochs = 109\n",
    "\n",
    "# --------------------------------------------\n",
    "num_frequencies = X.shape[1]\n",
    "num_timesteps   = X.shape[2]\n",
    "num_channels    = X.shape[3]\n",
    "input_shape = num_frequencies, num_timesteps, num_channels\n",
    "\n",
    "# DEFINE MODEL\n",
    "model = Sequential()\n",
    "model.add(MaxPooling2D(pool_size=(1, 3), input_shape=input_shape))\n",
    "model.add(Conv2D(32, kernel_size=(num_frequencies, 3),\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Conv2D(1, kernel_size=(1, 1), activation='sigmoid'))\n",
    "model.add(Lambda(lambda x: K.mean(x, axis=[1,2])))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 74, 1500, 1) (96,)\n",
      "(32, 74, 1500, 1) (32,)\n"
     ]
    }
   ],
   "source": [
    "t_ind = 96\n",
    "XTrain = X[:t_ind]\n",
    "YTrain = Y[:t_ind]\n",
    "XTest  = X[t_ind:]\n",
    "YTest  = Y[t_ind:]\n",
    "\n",
    "print(XTrain.shape, YTrain.shape)\n",
    "print(XTest.shape, YTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 32 samples\n",
      "Epoch 1/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.6877 - acc: 0.5000 - val_loss: 0.6804 - val_acc: 0.4688\n",
      "Epoch 2/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6855 - acc: 0.5208 - val_loss: 0.6719 - val_acc: 0.5625\n",
      "Epoch 3/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6739 - acc: 0.4896 - val_loss: 0.6867 - val_acc: 0.4375\n",
      "Epoch 4/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6549 - acc: 0.5208 - val_loss: 0.6535 - val_acc: 0.7812\n",
      "Epoch 5/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6564 - acc: 0.5938 - val_loss: 0.6448 - val_acc: 0.6250\n",
      "Epoch 6/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6437 - acc: 0.5625 - val_loss: 0.6269 - val_acc: 0.8750\n",
      "Epoch 7/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6272 - acc: 0.6042 - val_loss: 0.6214 - val_acc: 0.7188\n",
      "Epoch 8/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6574 - acc: 0.5521 - val_loss: 0.6067 - val_acc: 0.8750\n",
      "Epoch 9/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6255 - acc: 0.5938 - val_loss: 0.6006 - val_acc: 0.7188\n",
      "Epoch 10/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6193 - acc: 0.6667 - val_loss: 0.6467 - val_acc: 0.4375\n",
      "Epoch 11/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.6028 - acc: 0.6979 - val_loss: 0.6017 - val_acc: 0.6250\n",
      "Epoch 12/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.5957 - acc: 0.6562 - val_loss: 0.5721 - val_acc: 0.7188\n",
      "Epoch 13/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.5862 - acc: 0.6979 - val_loss: 0.5897 - val_acc: 0.6250\n",
      "Epoch 14/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.5650 - acc: 0.6771 - val_loss: 0.5452 - val_acc: 0.9375\n",
      "Epoch 15/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.5633 - acc: 0.6979 - val_loss: 0.6118 - val_acc: 0.6250\n",
      "Epoch 16/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.5599 - acc: 0.7292 - val_loss: 0.5200 - val_acc: 0.9375\n",
      "Epoch 17/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.5619 - acc: 0.7396 - val_loss: 0.5344 - val_acc: 0.7188\n",
      "Epoch 18/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.5304 - acc: 0.7500 - val_loss: 0.5029 - val_acc: 0.9062\n",
      "Epoch 19/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.5391 - acc: 0.7604 - val_loss: 0.4920 - val_acc: 0.9375\n",
      "Epoch 20/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.5016 - acc: 0.8229 - val_loss: 0.4813 - val_acc: 0.9375\n",
      "Epoch 21/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.5080 - acc: 0.8229 - val_loss: 0.4705 - val_acc: 0.9375\n",
      "Epoch 22/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4941 - acc: 0.8021 - val_loss: 0.4957 - val_acc: 0.7812\n",
      "Epoch 23/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.5174 - acc: 0.7917 - val_loss: 0.4919 - val_acc: 0.7812\n",
      "Epoch 24/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.4778 - acc: 0.8229 - val_loss: 0.4534 - val_acc: 0.9375\n",
      "Epoch 25/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.4613 - acc: 0.8229 - val_loss: 0.4641 - val_acc: 0.8125\n",
      "Epoch 26/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4648 - acc: 0.8542 - val_loss: 0.4259 - val_acc: 0.9688\n",
      "Epoch 27/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.4589 - acc: 0.7917 - val_loss: 0.4504 - val_acc: 0.8125\n",
      "Epoch 28/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.4372 - acc: 0.8333 - val_loss: 0.4288 - val_acc: 0.9062\n",
      "Epoch 29/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.4540 - acc: 0.8958 - val_loss: 0.4294 - val_acc: 0.8438\n",
      "Epoch 30/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4314 - acc: 0.8750 - val_loss: 0.3931 - val_acc: 0.9688\n",
      "Epoch 31/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4425 - acc: 0.8646 - val_loss: 0.3874 - val_acc: 0.9688\n",
      "Epoch 32/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4161 - acc: 0.8854 - val_loss: 0.4082 - val_acc: 0.9062\n",
      "Epoch 33/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4360 - acc: 0.8229 - val_loss: 0.4056 - val_acc: 0.9062\n",
      "Epoch 34/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4084 - acc: 0.8646 - val_loss: 0.3797 - val_acc: 0.9688\n",
      "Epoch 35/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4187 - acc: 0.8646 - val_loss: 0.3683 - val_acc: 0.9688\n",
      "Epoch 36/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4124 - acc: 0.8333 - val_loss: 0.3611 - val_acc: 0.9688\n",
      "Epoch 37/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3899 - acc: 0.8854 - val_loss: 0.3583 - val_acc: 0.9688\n",
      "Epoch 38/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3828 - acc: 0.9375 - val_loss: 0.3548 - val_acc: 0.9688\n",
      "Epoch 39/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3896 - acc: 0.8854 - val_loss: 0.3594 - val_acc: 0.9688\n",
      "Epoch 40/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4086 - acc: 0.8854 - val_loss: 0.3774 - val_acc: 0.9375\n",
      "Epoch 41/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3764 - acc: 0.9167 - val_loss: 0.3953 - val_acc: 0.8438\n",
      "Epoch 42/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3779 - acc: 0.8854 - val_loss: 0.3379 - val_acc: 0.9688\n",
      "Epoch 43/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3883 - acc: 0.8646 - val_loss: 0.3538 - val_acc: 0.9375\n",
      "Epoch 44/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3602 - acc: 0.8854 - val_loss: 0.3304 - val_acc: 0.9688\n",
      "Epoch 45/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3627 - acc: 0.9375 - val_loss: 0.3263 - val_acc: 0.9688\n",
      "Epoch 46/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3631 - acc: 0.9167 - val_loss: 0.3458 - val_acc: 0.9375\n",
      "Epoch 47/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3607 - acc: 0.8958 - val_loss: 0.3241 - val_acc: 0.9688\n",
      "Epoch 48/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3531 - acc: 0.9167 - val_loss: 0.3186 - val_acc: 0.9688\n",
      "Epoch 49/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3530 - acc: 0.9062 - val_loss: 0.3253 - val_acc: 0.9688\n",
      "Epoch 50/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3545 - acc: 0.8854 - val_loss: 0.3275 - val_acc: 0.9688\n",
      "Epoch 51/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3498 - acc: 0.9271 - val_loss: 0.3210 - val_acc: 0.9688\n",
      "Epoch 52/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3409 - acc: 0.9375 - val_loss: 0.3306 - val_acc: 0.9375\n",
      "Epoch 53/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3443 - acc: 0.8854 - val_loss: 0.3172 - val_acc: 0.9688\n",
      "Epoch 54/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3334 - acc: 0.9062 - val_loss: 0.3107 - val_acc: 0.9688\n",
      "Epoch 55/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3293 - acc: 0.9271 - val_loss: 0.3000 - val_acc: 0.9688\n",
      "Epoch 56/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3371 - acc: 0.9271 - val_loss: 0.3501 - val_acc: 0.9062\n",
      "Epoch 57/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3294 - acc: 0.9167 - val_loss: 0.2944 - val_acc: 0.9688\n",
      "Epoch 58/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3234 - acc: 0.9375 - val_loss: 0.2912 - val_acc: 0.9688\n",
      "Epoch 59/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3351 - acc: 0.9583 - val_loss: 0.2968 - val_acc: 0.9688\n",
      "Epoch 60/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3395 - acc: 0.9167 - val_loss: 0.3208 - val_acc: 0.9375\n",
      "Epoch 61/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3253 - acc: 0.9375 - val_loss: 0.3003 - val_acc: 0.9688\n",
      "Epoch 62/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3266 - acc: 0.9271 - val_loss: 0.3321 - val_acc: 0.9375\n",
      "Epoch 63/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3265 - acc: 0.9479 - val_loss: 0.2906 - val_acc: 0.9688\n",
      "Epoch 64/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3173 - acc: 0.9479 - val_loss: 0.2870 - val_acc: 0.9688\n",
      "Epoch 65/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3168 - acc: 0.9271 - val_loss: 0.3264 - val_acc: 0.9688\n",
      "Epoch 66/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3195 - acc: 0.9375 - val_loss: 0.2919 - val_acc: 0.9688\n",
      "Epoch 67/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3190 - acc: 0.9167 - val_loss: 0.2808 - val_acc: 0.9688\n",
      "Epoch 68/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3000 - acc: 0.9479 - val_loss: 0.3189 - val_acc: 0.9688\n",
      "Epoch 69/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3200 - acc: 0.9167 - val_loss: 0.2901 - val_acc: 0.9688\n",
      "Epoch 70/109\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2974 - acc: 0.9688 - val_loss: 0.3022 - val_acc: 0.9688\n",
      "Epoch 71/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.3052 - acc: 0.9167 - val_loss: 0.2978 - val_acc: 0.9688\n",
      "Epoch 72/109\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.3183 - acc: 0.9271 - val_loss: 0.2860 - val_acc: 0.9688\n",
      "Epoch 73/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.3197 - acc: 0.9167 - val_loss: 0.2717 - val_acc: 0.9688\n",
      "Epoch 74/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2921 - acc: 0.9479 - val_loss: 0.2750 - val_acc: 0.9688\n",
      "Epoch 75/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2980 - acc: 0.9688 - val_loss: 0.3421 - val_acc: 0.8750\n",
      "Epoch 76/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3015 - acc: 0.8750 - val_loss: 0.2669 - val_acc: 0.9688\n",
      "Epoch 77/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3127 - acc: 0.9375 - val_loss: 0.2742 - val_acc: 0.9688\n",
      "Epoch 78/109\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2921 - acc: 0.9479 - val_loss: 0.2806 - val_acc: 0.9688\n",
      "Epoch 79/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2938 - acc: 0.9479 - val_loss: 0.2743 - val_acc: 0.9688\n",
      "Epoch 80/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2950 - acc: 0.9375 - val_loss: 0.2776 - val_acc: 0.9688\n",
      "Epoch 81/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2895 - acc: 0.9479 - val_loss: 0.2763 - val_acc: 0.9688\n",
      "Epoch 82/109\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2925 - acc: 0.9688 - val_loss: 0.2557 - val_acc: 0.9688\n",
      "Epoch 83/109\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2899 - acc: 0.9688 - val_loss: 0.2576 - val_acc: 0.9688\n",
      "Epoch 84/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2818 - acc: 0.9479 - val_loss: 0.2565 - val_acc: 0.9688\n",
      "Epoch 85/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2870 - acc: 0.9479 - val_loss: 0.2635 - val_acc: 0.9688\n",
      "Epoch 86/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2825 - acc: 0.9688 - val_loss: 0.2511 - val_acc: 0.9688\n",
      "Epoch 87/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2876 - acc: 0.9479 - val_loss: 0.2793 - val_acc: 0.9688\n",
      "Epoch 88/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2908 - acc: 0.9271 - val_loss: 0.2492 - val_acc: 0.9688\n",
      "Epoch 89/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2860 - acc: 0.9375 - val_loss: 0.2486 - val_acc: 0.9688\n",
      "Epoch 90/109\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2761 - acc: 0.9583 - val_loss: 0.2846 - val_acc: 1.0000\n",
      "Epoch 91/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2826 - acc: 0.9583 - val_loss: 0.2604 - val_acc: 0.9688\n",
      "Epoch 92/109\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2786 - acc: 0.9271 - val_loss: 0.2459 - val_acc: 0.9688\n",
      "Epoch 93/109\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2748 - acc: 0.9688 - val_loss: 0.2451 - val_acc: 0.9688\n",
      "Epoch 94/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2861 - acc: 0.9479 - val_loss: 0.2479 - val_acc: 0.9688\n",
      "Epoch 95/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2809 - acc: 0.9688 - val_loss: 0.2439 - val_acc: 0.9688\n",
      "Epoch 96/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2824 - acc: 0.9583 - val_loss: 0.2814 - val_acc: 1.0000\n",
      "Epoch 97/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2708 - acc: 0.9583 - val_loss: 0.2445 - val_acc: 0.9688\n",
      "Epoch 98/109\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2627 - acc: 0.9688 - val_loss: 0.2439 - val_acc: 0.9688\n",
      "Epoch 99/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2698 - acc: 0.9583 - val_loss: 0.2433 - val_acc: 0.9688\n",
      "Epoch 100/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2699 - acc: 0.9792 - val_loss: 0.2527 - val_acc: 0.9688\n",
      "Epoch 101/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2670 - acc: 0.9688 - val_loss: 0.2376 - val_acc: 0.9688\n",
      "Epoch 102/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2631 - acc: 0.9896 - val_loss: 0.2382 - val_acc: 0.9688\n",
      "Epoch 103/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2653 - acc: 0.9688 - val_loss: 0.2495 - val_acc: 0.9688\n",
      "Epoch 104/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2640 - acc: 0.9688 - val_loss: 0.2393 - val_acc: 0.9688\n",
      "Epoch 105/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2660 - acc: 0.9479 - val_loss: 0.2888 - val_acc: 1.0000\n",
      "Epoch 106/109\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2574 - acc: 0.9583 - val_loss: 0.2351 - val_acc: 0.9688\n",
      "Epoch 107/109\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2696 - acc: 0.9792 - val_loss: 0.2362 - val_acc: 0.9688\n",
      "Epoch 108/109\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.2628 - acc: 0.9479 - val_loss: 0.2321 - val_acc: 0.9688\n",
      "Epoch 109/109\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2607 - acc: 0.9479 - val_loss: 0.2502 - val_acc: 0.9688\n",
      "Test loss: 0.25023573637\n",
      "Test accuracy: 0.96875\n"
     ]
    }
   ],
   "source": [
    "model.fit(XTrain, YTrain,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(XTest, YTest))\n",
    "score = model.evaluate(XTest, YTest, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = '../models/keras/'\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "model.save(os.path.join(model_path, 'cnn_on_spectros_{:2.2f}.h5'.format(score[1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

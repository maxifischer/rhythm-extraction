{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import madmom\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocessing import get_dataset, load_rhythm_feature_db\n",
    "from models import OLSPatchRegressor\n",
    "from utils import cv\n",
    "import visualize\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "MUSIC = 1\n",
    "SPEECH = 0\n",
    "\n",
    "na = np.newaxis\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "\n",
    "# --------------- FLAGS ----------\n",
    "DATA = \"SPECTRO\" # \"SPECTRO\"\n",
    "MODEL = \"CNN\"\n",
    "\n",
    "assert DATA in [\"RHYTHM\", \"SPECTRO\"]\n",
    "assert MODEL in [\"CNN\", \"Linear\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "music_dir  = '../data/music_speech/music_wav/'\n",
    "speech_dir = '../data/music_speech/speech_wav/'\n",
    "\n",
    "\n",
    "def get_spectro_data():\n",
    "\n",
    "    max_samples = -1\n",
    "\n",
    "    X, Y = get_dataset(music_dir, speech_dir, hpool=0, wpool=0, \n",
    "                       num_samples=max_samples, shuffle=True, reload=False,\n",
    "                       window=np.hanning, fps=100, num_bands=3, fmin=30, fmax=17000,\n",
    "                       fft_sizes=[1024, 2048, 4096]\n",
    "                      )\n",
    "    print('Train Set Shape')\n",
    "    print(X.shape, Y.shape)\n",
    "\n",
    "    Y = (Y + 1) / 2 \n",
    "    return X, Y\n",
    " \n",
    "\n",
    "def get_rhythm_data():\n",
    "\n",
    "    X, Y = load_rhythm_feature_db(music_dir, speech_dir, num_samples=-1)\n",
    "\n",
    "    # change -1, 1 labels to 0,1\n",
    "    Y = (Y + 1) / 2 \n",
    "\n",
    "    # X is in (N,L,D) format\n",
    "\n",
    "    X = X[:,na,:,:] # dont conv over the number of models\n",
    "    return X, Y\n",
    "\n",
    "X, Y = get_rhythm_data() if DATA == \"RHYTHM\" else get_spectro_data()\n",
    "\n",
    "batch_size = 8\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    "\n",
    "# --------------------------------------------\n",
    "num_frequencies = X.shape[1]\n",
    "num_timesteps   = X.shape[2]\n",
    "num_channels    = X.shape[3]\n",
    "filter_time_size = 3\n",
    "input_shape = num_frequencies, num_timesteps, num_channels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)\n",
    "\n",
    "CNN = None\n",
    "def get_cnn(input_shape=(input_shape), reinit=False):\n",
    "    global CNN\n",
    "    if CNN is None:\n",
    "        \n",
    "        # DEFINE MODEL\n",
    "        model = Sequential()\n",
    "        model.add(MaxPooling2D(pool_size=(1, 3), input_shape=input_shape))\n",
    "        model.add(Conv2D(32, kernel_size=(num_frequencies, filter_time_size),\n",
    "                         activation='relu'))\n",
    "\n",
    "        model.add(Conv2D(1, kernel_size=(1, 1), activation='sigmoid'))\n",
    "        model.add(Lambda(lambda x: K.mean(x, axis=[1,2])))\n",
    "\n",
    "        model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        CNN = model\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    else:\n",
    "        model = CNN\n",
    "        reset_weights(model)\n",
    "        return model\n",
    "\n",
    "LINEAR = None\n",
    "def get_linear(input_shape=(input_shape), reinit=False):\n",
    "    global LINEAR\n",
    "    if LINEAR is None:\n",
    "        \n",
    "        # DEFINE MODEL\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(1, kernel_size=(num_frequencies, filter_time_size),\n",
    "                         activation='sigmoid',\n",
    "                         input_shape=input_shape))\n",
    "\n",
    "        model.add(Lambda(lambda x: K.mean(x, axis=[1,2])))\n",
    "\n",
    "        model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        LINEAR = model\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    else:\n",
    "        model = LINEAR\n",
    "        reset_weights(model)\n",
    "        return model\n",
    "\n",
    "get_model = get_cnn if MODEL == \"CNN\" else get_linear\n",
    "\n",
    "\n",
    "train_model = lambda model, X, Y: model.fit(X, Y,\n",
    "                                        batch_size=batch_size,\n",
    "                                        epochs=epochs,\n",
    "                                        verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "split = 100\n",
    "Xtrain, Ytrain, Xtest, Ytest = X[:split], Y[:split], X[split:], Y[split:]\n",
    "model_dir = '../models/keras/'\n",
    "model_path = os.path.join(model_dir, '{}_on_{}-filter{}-evaluation.h5'.format(MODEL.lower(), DATA.lower(), filter_time_size))\n",
    "# evaluate using train-test split\n",
    "model = get_model()\n",
    "try:\n",
    "    model.load_weights(model_path)\n",
    "    print(\"loaded model\")\n",
    "except OSError:\n",
    "    print(\"train model\")\n",
    "    train_model(model, Xtrain, Ytrain)\n",
    "    \n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, Ytest, verbose=0)\n",
    "print(\"Score\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# evaluate the different channels\n",
    "import matplotlib\n",
    "\n",
    "os.makedirs(\"evaluate\", exist_ok=True)\n",
    "\n",
    "music_sample = Xtest[Ytest==MUSIC][0][None,...]\n",
    "speech_sample = Xtest[Ytest!=MUSIC][0][None,...]\n",
    "\n",
    "# plot the filters\n",
    "if DATA == \"SPECTRO\":\n",
    "    # get the first layer with weights:\n",
    "    W_all, i = None, -1\n",
    "    while W_all is None:\n",
    "        i += 1\n",
    "        try:\n",
    "            W_all = model.layers[i].get_weights()[0]\n",
    "        except: pass\n",
    "        \n",
    "    inspect_model = Model(inputs=model.input, outputs=model.layers[i].output)\n",
    "    music_activation = inspect_model.predict(music_sample)[0,0]\n",
    "    speech_activation = inspect_model.predict(speech_sample)[0,0]\n",
    "    \n",
    "    \n",
    "    time = np.arange(0,30,30/music_activation.shape[0])\n",
    "    \n",
    "    \n",
    "    num_output_channels = W_all.shape[-1]\n",
    "    \n",
    "    for output_channel in range(num_output_channels):\n",
    "        W = W_all[:,:,:,output_channel]\n",
    "        bound = np.max(np.absolute(W))\n",
    "        norm = matplotlib.colors.Normalize(vmin=-bound, vmax=bound)\n",
    "\n",
    "        num_filters = W.shape[-1]\n",
    "        num_subplots = 3*num_filters\n",
    "\n",
    "        fig = plt.figure(figsize=(12,9))\n",
    "\n",
    "        for channel in range(num_filters):\n",
    "            w_channel = W[:,:,channel]\n",
    "            w_plus = np.maximum(w_channel, 0)\n",
    "            w_minus = -np.maximum(-w_channel, 0)\n",
    "            plt.subplot(num_filters+1,3,1 + channel*3)\n",
    "            plt.imshow(w_channel, cmap=\"PuOr\", norm=norm)\n",
    "            plt.colorbar()\n",
    "\n",
    "            plt.subplot(num_filters+1,3,2 + channel*3)\n",
    "            plt.imshow(w_plus, cmap=\"PuOr\", norm=norm)\n",
    "            plt.colorbar()\n",
    "            if MODEL==\"LINEAR\":\n",
    "                plt.title(\"Evidence for music\")\n",
    "\n",
    "            plt.subplot(num_filters+1,3,3 + channel*3)\n",
    "            plt.imshow(w_minus, cmap=\"PuOr\", norm=norm)\n",
    "            plt.colorbar()\n",
    "            if MODEL==\"LINEAR\":\n",
    "                plt.title(\"Evidence for speech\")\n",
    "        \n",
    "        plt.subplot(num_filters+1, 1, num_filters+1)\n",
    "        plt.plot(time, music_activation[:,output_channel], label=\"Music\")\n",
    "        plt.plot(time, speech_activation[:,output_channel], label=\"Speech\")\n",
    "        plt.xlabel(\"Time/s\")\n",
    "        plt.ylabel(\"Channel activation\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"evaluate/{}-spectro-filters-{}-channel{}.png\".format(MODEL, filter_time_size, output_channel))\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
